{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1JB-JHuBQfT"
      },
      "source": [
        "# Supervised Learning Lab\n",
        "### YOUR NAME HERE\n",
        "In this lab you will be experimenting with several supervised learning methods.  Let's start by importing a few things.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoEm9c3GBQfV"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()  # for plot styling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9BsVE9EBQfW"
      },
      "source": [
        "We first generate some dummy data from random samples in a 2D space from 4 clusters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liPeX-UUBQfX"
      },
      "outputs": [],
      "source": [
        "n_samples = 64\n",
        "variance = 0.1\n",
        "\n",
        "# 4 clusters in a 2D space\n",
        "centers = np.array([[0, 0],\n",
        "                    [0, 1],\n",
        "                    [1, 0],\n",
        "                    [1, 1]])\n",
        "\n",
        "X, y = make_blobs(n_samples,\n",
        "                  centers=centers,\n",
        "                  cluster_std = np.sqrt(variance),\n",
        "                  shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56a5QlLiBQfX"
      },
      "source": [
        "We now define a function to create and train a kNN classifier.  Calling this function will generate some print statements that show the confusion matrix output.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcD0-qCrBQfX"
      },
      "outputs": [],
      "source": [
        "def run_knn(X_train, y_train, X_test, y_test, k=5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        "         .format(knn.score(X_train, y_train)))\n",
        "    print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        "         .format(knn.score(X_test, y_test)))\n",
        "    pred = knn.predict(X_test)\n",
        "    print(confusion_matrix(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIjgce3NBQfX"
      },
      "source": [
        "## Exercise 1:\n",
        "Use matplot lib to plot the groups of the ``X`` values coloring the points according to their labels (``y``).  Then add two lines to the plot that show your approximation of where linear decision boundaries might lie to optimally separate the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR61kSboBQfX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1ZPH7FaBQfX"
      },
      "source": [
        "Next, lets see how well this data can be classified with kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3s9FZOMBQfX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "run_knn(X_train, y_train, X_test, y_test, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_nTptAqBQfY"
      },
      "source": [
        "## Exercise 2:\n",
        "Experiment in the next cell with adjusting the variance when building additional random datasets.  Write a few statements in your reflection below about how the variance affected the accuracy and whether overfitting occured.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeBzZE0BQfY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGracRrfBQfY"
      },
      "source": [
        "### Reflection\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y95xxIrNBQfY"
      },
      "source": [
        "Next, we import some data.  \n",
        "\n",
        "## Exercise 3:\n",
        "Read through the website: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset where the following dataset was obtained.  Create a feature description below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0XObnp-BQfY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLobDfRPBQfY"
      },
      "source": [
        "## Feature Description\n",
        "TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTLcsqMeBQfY"
      },
      "source": [
        "## Exercise 4:\n",
        "Extract the age and hypertension columns as input features and stroke as output labels from the dataframe.  Scale and split the data and then run the knn training and evaluation.  \n",
        "\n",
        "Fill out the Reflection cell below describing what you observe.  Make sure you identify if overfitting is occuring.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQizpNk6BQfY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7aasPNIBQfY"
      },
      "source": [
        "### Reflection\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3UZo9sjBQfY"
      },
      "source": [
        "## Exercise 5:\n",
        "There are a few things going on here.  First, we have a significant class imbalance problem.  Write a 1-liner to calculate the ratio of stroke to non stroke patients in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVMyRn4pBQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrU7osj5BQfZ"
      },
      "source": [
        "OK, so that is a really imbalanced class.  To help resolve this, we are going to experiment with random oversampling and undersampling in our training dataset.  \n",
        "\n",
        "## Exercise 6:\n",
        "Figure out which class has fewer and how many samples exist for that class.  Use the ``sample()`` method to undersample the data: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html  Join the results back into a single dataframe that represents the undersampled data (appropriately named).\n",
        "\n",
        "Confirm the number of samples in each class using ``value_counts()``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaRWd4lpBQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V32udPmFBQfZ"
      },
      "source": [
        "## Exercise 7:\n",
        "Next, re-run the kNN training and determine the updated accuracy and confusion matrix.  Write a few statements below for your reflection on the results.  Make sure you answer the question, did overfitting occur?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgM5vS6-BQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2we9PKQzBQfZ"
      },
      "source": [
        "### Reflection\n",
        "\n",
        "TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbs6t_u8BQfZ"
      },
      "source": [
        "## Exercise 8:\n",
        "Next, you should oversample the data and store the results in an appropriately-named dataframe.  Again, you should use ``sample()``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgpsd1hFBQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NnpZlRUBQfZ"
      },
      "source": [
        "## Exercise 9:\n",
        "Next, re-run the kNN training and determine the updated accuracy and confusion matrix.  Write a few statements below for your reflection on the results.  Make sure you answer the question, did overfitting occur?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wf3Bkl6BQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZLnlVhWBQfZ"
      },
      "source": [
        "### Reflection:\n",
        "\n",
        "TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPXduGqJBQfZ"
      },
      "source": [
        "## Exercise 10:\n",
        "Next, you should try at least two other combinations of features to see what affects they have on accuracy.  At least one of your experiments should include categorical variables that have been converted to numerical.  You should also experiment with at least 2 additional values of k.  In total, you should run at least 5 experiments, and you should document the results in a table below in the reflection section.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKxBI4h3BQfZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnEN1QMwBQfZ"
      },
      "source": [
        "### Reflection\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INv17EAmBQfa"
      },
      "source": [
        "## Exercise 11:\n",
        "Next, you should experiment with a couple of different distance metrics.  To change the metric, you should add a parameter (with an appropriate default) to the run_knn function and use the parameter to set the metric like this: ``KNeighborsClassifier(n_neighbors=2, metric=metric)``.  Metric options can be seen here: https://scikit-learn.org/0.24/modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric\n",
        "\n",
        "Try at least 3 different metrics with the \"best\" accuracy configuration.  Document the results in a table in the reflection section below.  Please also record any observations about using different metrics.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASCoYl9ABQfa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7umKBafBQfa"
      },
      "source": [
        "### Reflection\n",
        "TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}